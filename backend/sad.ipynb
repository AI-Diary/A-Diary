{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mxnet in c:\\users\\user\\anaconda3\\lib\\site-packages (1.7.0.post2)\n",
      "Requirement already satisfied: requests<2.19.0,>=2.18.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mxnet) (2.18.4)\n",
      "Requirement already satisfied: numpy<1.17.0,>=1.8.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mxnet) (1.16.6)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mxnet) (0.8.4)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet) (1.22)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet) (2022.12.7)\n",
      "Requirement already satisfied: gluonnlp in c:\\users\\user\\anaconda3\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (4.59.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gluonnlp) (1.16.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from gluonnlp) (20.9)\n",
      "Requirement already satisfied: cython in c:\\users\\user\\anaconda3\\lib\\site-packages (from gluonnlp) (0.29.23)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging->gluonnlp) (2.4.7)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\user\\anaconda3\\lib\\site-packages (0.1.97)\n",
      "Requirement already satisfied: transformers==3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers==3.0.2) (0.1.97)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers==3.0.2) (4.59.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers==3.0.2) (2021.4.4)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers==3.0.2) (0.0.53)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers==3.0.2) (2.18.4)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers==3.0.2) (0.8.1rc1)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers==3.0.2) (20.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers==3.0.2) (3.0.12)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers==3.0.2) (1.16.6)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers==3.0.2) (2022.12.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers==3.0.2) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers==3.0.2) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers==3.0.2) (1.22)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from sacremoses->transformers==3.0.2) (1.0.1)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (4.4.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install mxnet\n",
    "%pip install gluonnlp pandas tqdm\n",
    "%pip install sentencepiece\n",
    "%pip install transformers==3.0.2\n",
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kobert'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USER\\OneDrive\\바탕 화면\\pt\\sad.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/pt/sad.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm, tqdm_notebook\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/pt/sad.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m#kobert\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/pt/sad.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkobert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_tokenizer\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/pt/sad.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkobert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpytorch_kobert\u001b[39;00m \u001b[39mimport\u001b[39;00m get_pytorch_kobert_model\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kobert'"
     ]
    }
   ],
   "source": [
    "# torch\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "#kobert\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USER\\OneDrive\\바탕 화면\\pt\\sad.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/pt/sad.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#GPU 사용\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/pt/sad.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/pt/sad.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#BERT 모델, Vocabulary 불러오기 필수\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/pt/sad.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m bertmodel, vocab \u001b[39m=\u001b[39m get_pytorch_kobert_model()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#GPU 사용\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "#BERT 모델, Vocabulary 불러오기 필수\n",
    "bertmodel, vocab = get_pytorch_kobert_model()\n",
    "\n",
    "\n",
    "# KoBERT에 입력될 데이터셋 정리\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))  \n",
    "\n",
    "# 모델 정의\n",
    "class BERTClassifier(nn.Module): ## 클래스를 상속\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=6,   ##클래스 수 조정##\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)\n",
    "\n",
    "# Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 32\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 20\n",
    "max_grad_norm = 1\n",
    "log_interval = 100\n",
    "learning_rate =  5e-5\n",
    "\n",
    "## 학습 모델 로드\n",
    "# PATH = 'drive/MyDrive/colab/StoryFlower/bert/'\n",
    "model = torch.load(\"SentimentAnalysisKOBert.pt\")  # 전체 모델을 통째로 불러옴, 클래스 선언 필수\n",
    "model.load_state_dict(torch.load(\"SentimentAnalysisKOBert_StateDict.pt\"))  # state_dict를 불러 온 후, 모델에 저장\n",
    "\n",
    "#토큰화\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "def new_softmax(a) : \n",
    "    c = np.max(a) # 최댓값\n",
    "    exp_a = np.exp(a-c) # 각각의 원소에 최댓값을 뺀 값에 exp를 취한다. (이를 통해 overflow 방지)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = (exp_a / sum_exp_a) * 100\n",
    "    return np.round(y, 3)\n",
    "\n",
    "\n",
    "# 예측 모델 설정\n",
    "def predict(predict_sentence):\n",
    "\n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "        test_eval=[]\n",
    "        for i in out:\n",
    "            logits=i\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            min_v = min(logits)\n",
    "            total = 0\n",
    "            probability = []\n",
    "            logits = np.round(new_softmax(logits), 3).tolist()\n",
    "            for logit in logits:\n",
    "                print(logit)\n",
    "                probability.append(np.round(logit, 3))\n",
    "\n",
    "            if np.argmax(logits) == 0:  emotion = \"기쁨\"\n",
    "            elif np.argmax(logits) == 1: emotion = \"불안\"\n",
    "            elif np.argmax(logits) == 2: emotion = '당황'\n",
    "            elif np.argmax(logits) == 3: emotion = '슬픔'\n",
    "            elif np.argmax(logits) == 4: emotion = '분노'\n",
    "            elif np.argmax(logits) == 5: emotion = '상처'\n",
    "\n",
    "            probability.append(emotion)\n",
    "            print(probability)\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USER\\OneDrive\\바탕 화면\\pt\\backend\\sad.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/pt/backend/sad.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(hi)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hi' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
