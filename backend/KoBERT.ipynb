{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3==1.15.18 in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (1.15.18)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from boto3==1.15.18) (0.3.7)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from boto3==1.15.18) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.19.0,>=1.18.18 in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from boto3==1.15.18) (1.18.18)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20 in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from botocore<1.19.0,>=1.18.18->boto3==1.15.18) (1.22)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from botocore<1.19.0,>=1.18.18->boto3==1.15.18) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.19.0,>=1.18.18->boto3==1.15.18) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: gluonnlp==0.10.0 in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: cython in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from gluonnlp==0.10.0) (0.29.33)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from gluonnlp==0.10.0) (23.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from gluonnlp==0.10.0) (1.21.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: onnxruntime==1.8.0 in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from onnxruntime==1.8.0) (1.21.6)\n",
      "Requirement already satisfied: protobuf in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from onnxruntime==1.8.0) (4.22.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from onnxruntime==1.8.0) (23.3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sentencepiece==0.1.96 in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (0.1.96)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch==1.10.1 in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (1.10.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from torch==1.10.1) (4.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers==4.8.1 in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (4.8.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from transformers==4.8.1) (4.65.0)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from transformers==4.8.1) (0.0.53)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from transformers==4.8.1) (2.18.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from transformers==4.8.1) (23.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from transformers==4.8.1) (6.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from transformers==4.8.1) (2022.10.31)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from transformers==4.8.1) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from transformers==4.8.1) (3.10.3)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Using cached tokenizers-0.10.3-cp37-cp37m-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from transformers==4.8.1) (1.21.6)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from transformers==4.8.1) (0.0.12)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from huggingface-hub==0.0.12->transformers==4.8.1) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from tqdm>=4.27->transformers==4.8.1) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from importlib-metadata->transformers==4.8.1) (3.15.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from requests->transformers==4.8.1) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from requests->transformers==4.8.1) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from requests->transformers==4.8.1) (1.22)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from requests->transformers==4.8.1) (2.6)\n",
      "Requirement already satisfied: joblib in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from sacremoses->transformers==4.8.1) (1.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from sacremoses->transformers==4.8.1) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\desktop\\kobert\\.conda\\lib\\site-packages (from sacremoses->transformers==4.8.1) (8.1.3)\n",
      "Installing collected packages: tokenizers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.8.1rc1\n",
      "    Uninstalling tokenizers-0.8.1rc1:\n",
      "      Successfully uninstalled tokenizers-0.8.1rc1\n",
      "Successfully installed tokenizers-0.10.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#requirements\n",
    "%pip install boto3==1.15.18\n",
    "%pip install gluonnlp==0.10.0\n",
    "%pip install onnxruntime==1.8.0\n",
    "%pip install sentencepiece==0.1.96\n",
    "%pip install torch==1.10.1\n",
    "%pip install transformers==4.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
      "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to c:\\users\\asus\\appdata\\local\\temp\\pip-req-build-12ouro86\n",
      "  Resolved https://****@github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: kobert\n",
      "  Building wheel for kobert (setup.py): started\n",
      "  Building wheel for kobert (setup.py): finished with status 'done'\n",
      "  Created wheel for kobert: filename=kobert-0.2.3-py3-none-any.whl size=15806 sha256=ebe079d6bd06828232977cacc5a8c76bf9b8d131f99ff2a2546e7912a88df501\n",
      "  Stored in directory: C:\\Users\\ASUS\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-dmgzames\\wheels\\d3\\68\\ca\\334747dfb038313b49cf71f84832a33372f3470d9ddfd051c0\n",
      "Successfully built kobert\n",
      "Installing collected packages: kobert\n",
      "  Attempting uninstall: kobert\n",
      "    Found existing installation: kobert 0.2.3\n",
      "    Uninstalling kobert-0.2.3:\n",
      "      Successfully uninstalled kobert-0.2.3\n",
      "Successfully installed kobert-0.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet 'https://****@github.com/SKTBrain/KoBERT.git' 'C:\\Users\\ASUS\\AppData\\Local\\Temp\\pip-req-build-12ouro86'\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade --no-deps --force-reinstall git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "#kobert\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. c:\\Users\\ASUS\\Desktop\\KoBERT\\.cache\\kobert_v1.zip\n",
      "using cached model. c:\\Users\\ASUS\\Desktop\\KoBERT\\.cache\\kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'GELUActivation' on <module 'transformers.activations' from 'c:\\\\Users\\\\ASUS\\\\Desktop\\\\KoBERT\\\\.conda\\\\lib\\\\site-packages\\\\transformers\\\\activations.py'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14192\\2327221861.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;31m## 학습 모델 로드\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;31m# PATH = 'drive/MyDrive/colab/StoryFlower/bert/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SentimentAnalysisKOBert.pt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 전체 모델을 통째로 불러옴, 클래스 선언 필수\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SentimentAnalysisKOBert_StateDict.pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# state_dict를 불러 온 후, 모델에 저장\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\Desktop\\KoBERT\\.conda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    605\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\Desktop\\KoBERT\\.conda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m    880\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\Desktop\\KoBERT\\.conda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mfind_class\u001b[1;34m(self, mod_name, name)\u001b[0m\n\u001b[0;32m    873\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfind_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m             \u001b[0mmod_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_module_mapping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 875\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m     \u001b[1;31m# Load the data (which may in turn use `persistent_load` to load tensors)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'GELUActivation' on <module 'transformers.activations' from 'c:\\\\Users\\\\ASUS\\\\Desktop\\\\KoBERT\\\\.conda\\\\lib\\\\site-packages\\\\transformers\\\\activations.py'>"
     ]
    }
   ],
   "source": [
    "#GPU 사용\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "#BERT 모델, Vocabulary 불러오기 필수\n",
    "bertmodel, vocab = get_pytorch_kobert_model()\n",
    "\n",
    "\n",
    "# KoBERT에 입력될 데이터셋 정리\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))  \n",
    "\n",
    "# 모델 정의\n",
    "class BERTClassifier(nn.Module): ## 클래스를 상속\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=6,   ##클래스 수 조정##\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)\n",
    "\n",
    "# Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 32\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 20\n",
    "max_grad_norm = 1\n",
    "log_interval = 100\n",
    "learning_rate =  5e-5\n",
    "\n",
    "## 학습 모델 로드\n",
    "# PATH = 'drive/MyDrive/colab/StoryFlower/bert/'\n",
    "model = torch.load(\"SentimentAnalysisKOBert.pt\", map_location='cpu')  # 전체 모델을 통째로 불러옴, 클래스 선언 필수\n",
    "model.load_state_dict(torch.load(\"SentimentAnalysisKOBert_StateDict.pt\"))  # state_dict를 불러 온 후, 모델에 저장\n",
    "\n",
    "#토큰화\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "def new_softmax(a) : \n",
    "    c = np.max(a) # 최댓값\n",
    "    exp_a = np.exp(a-c) # 각각의 원소에 최댓값을 뺀 값에 exp를 취한다. (이를 통해 overflow 방지)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = (exp_a / sum_exp_a) * 100\n",
    "    return np.round(y, 3)\n",
    "\n",
    "\n",
    "# 예측 모델 설정\n",
    "def predict(predict_sentence):\n",
    "\n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "        test_eval=[]\n",
    "        for i in out:\n",
    "            logits=i\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            min_v = min(logits)\n",
    "            total = 0\n",
    "            probability = []\n",
    "            logits = np.round(new_softmax(logits), 3).tolist()\n",
    "            for logit in logits:\n",
    "                print(logit)\n",
    "                probability.append(np.round(logit, 3))\n",
    "\n",
    "            if np.argmax(logits) == 0:  emotion = \"기쁨\"\n",
    "            elif np.argmax(logits) == 1: emotion = \"불안\"\n",
    "            elif np.argmax(logits) == 2: emotion = '당황'\n",
    "            elif np.argmax(logits) == 3: emotion = '슬픔'\n",
    "            elif np.argmax(logits) == 4: emotion = '분노'\n",
    "            elif np.argmax(logits) == 5: emotion = '상처'\n",
    "\n",
    "            probability.append(emotion)\n",
    "            print(probability)\n",
    "    return probability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
